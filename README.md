# linc-sandbox-cloud-data-pipeline

Hands-on cloud data processing sandbox led at IFSP Campinas, designed to connect students to real public and partner datasets through a structured 4-stage pipeline.

This repository supports educational, research and innovation activities, with strong emphasis on practical skills, reproducibility, cost-awareness and real-world data challenges.

---

## Leadership and institutional context

This project is led by **Leandro Ataíde Barbosa de Oliveira**, faculty member at IFSP Campinas, researcher and project lead within the LINC (research and innovation group).

The repository is currently hosted under a personal GitHub account for pilot submissions and cloud credit applications. The project is designed to scale to an institutional or research-group repository in later stages.

---

## Institutional and professional references

- IFSP Campinas (official portal): https://portal.cmp.ifsp.edu.br/
- Curriculum Lattes: http://lattes.cnpq.br/8977107816939407
- GitHub profile: https://github.com/Leo4US
- LinkedIn Page (LINC Sandbox): https://www.linkedin.com/company/linc-sandbox/about/

All public communication of events and validated results will be shared through the LinkedIn Page.

---

## Project goal

The main goal of this sandbox is to enable students to acquire **hands-on experience in cloud-based data processing**, moving beyond theoretical exposure and simulated examples.

Without access to real datasets and controlled cloud environments, it is difficult for students to develop operational skills. This project addresses that gap through a staged, supervised and auditable pipeline.

---

## The 4-stage pipeline

### Stage 1 — Theory and commands (hands-on foundations)
Students learn and apply core commands and patterns for:
- data ingestion and normalization  
- data cleaning and validation  
- exploratory analysis  
- reproducible workflows and documentation  

### Stage 2 — Modeling and simulation (no cloud credits required)
Architectures and pipelines are tested locally using cloud-like simulations:
- object storage simulation (S3-like)
- service emulation where applicable
- containerized execution for reproducibility  

This stage allows experimentation without financial cost.

### Stage 3 — Controlled practical tests (“Aquarium mode”)
Students execute supervised mini-projects under strict guardrails:
- limited datasets and predefined tasks  
- logging, monitoring and artifact generation  
- emphasis on cost-awareness and data quality  

### Stage 4 — Partner challenge and hackathon (core focus)
A public institution or company proposes a real-world problem using:
- public datasets, or  
- anonymized datasets, or  
- synthetic datasets that mirror real structures  

Students work in teams during a structured hackathon and deliver:
- a minimal, reproducible data pipeline  
- validation and quality checks  
- a technical report or dashboard  
- a short partner-facing technical brief  

Detailed description: `docs/03_hackathon_etapa4.md`

---

## Compliance and data ethics

- Preference for open and public datasets in early stages  
- Anonymization or synthetic data for partner challenges  
- Minimal data exposure and clear access rules  
- Alignment with LGPD principles  

See: `docs/06_lgpd_e_dados.md`

---

## Current status

- Pilot phase  
- Initial cohort: students from TADS and postgraduate programs in Data Science (IFSP Campinas)  
- Next milestone: first supervised challenge with an external partner
